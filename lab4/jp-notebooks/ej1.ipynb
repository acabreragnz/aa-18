{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "\n",
    "sys.path.append('../../../lab')# permite importar modulos locales\n",
    "sys.path.append('../../../lab/lab4/ej1/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans.k_means import k_means\n",
    "from kmeans.kmeans_helper import print_results, print_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacioón algoritmo K-Means\n",
    "\n",
    "\n",
    "\n",
    "Pseudocodigo:\n",
    "\n",
    "k = número de clusters\n",
    "\n",
    "1) Inicializar k clusters con sus centroides µ1, µ2, µ3 .... µk de forma aleatoria. \n",
    "2) while not converge:\n",
    "    for i in range(dataset):\n",
    "        \n",
    "        ck = argmin|| xi - µk||^2\n",
    "        \n",
    "        for j in range(k):\n",
    "            µj = (∑ 1 {c[i] = j}xi)/ (∑ 1{c[i] = j}) con i= 1..m\n",
    "            {c[i] = 1} si c[i] = j, 0 en caso contrario)\n",
    "            \n",
    "            \n",
    "Seleccionando k puntos de los datos que van a ser clasificados.\n",
    "Marcamos que el algoritmo converge cuando los centroides de la iteración anterior coinciden con los centroides actuales, o cuando se supera cierto número de iteraciones.\n",
    "            \n",
    "\n",
    "Para la implementación del algoritmo se crearon dos clases auxiliares:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points: Representa los vectores que van a ser clasificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Point:\n",
    "\n",
    "    def __init__(self, coordinates):\n",
    "        self.coordinates = coordinates\n",
    "        self.dimension = len(coordinates)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Coordinates: ' + str(self.coordinates) + \\\n",
    "               ' -> Dimension: ' + str(self.dimension)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster: Representa los clusters generado por el algoritmo. Cada cluster contiene el centroide y los puntos que son asignados luego de la clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Cluster:\n",
    "\n",
    "    def __init__(self, points):\n",
    "        if len(points) == 0:\n",
    "            raise Exception(\"Cluster cannot have 0 Points\")\n",
    "        else:\n",
    "            self.points = points\n",
    "            self.dimension = points[0].dimension\n",
    "\n",
    "        # Check that all elements of the cluster have the same dimension\n",
    "        for p in points:\n",
    "            if p.dimension != self.dimension:\n",
    "                raise Exception(\n",
    "                    \"Point %s has dimension %d different with %d from the rest \"\n",
    "                    \"of points\") % (p, len(p), self.dimension)\n",
    "\n",
    "        # Calculate Centroid\n",
    "        self.centroid = self.calculate_centroid()\n",
    "        self.converge = False\n",
    "        \n",
    "    def calculate_centroid(self):\n",
    "\n",
    "        sum_coordinates = np.zeros (self.dimension)\n",
    "        for p in self.points:\n",
    "            for i, x in enumerate (p.coordinates):\n",
    "                sum_coordinates[i] += x\n",
    "\n",
    "        return (sum_coordinates / len (self.points)).tolist ()  \n",
    "    \n",
    "    def update_cluster(self, points):\n",
    "\n",
    "        old_centroid = self.centroid\n",
    "        self.points = points\n",
    "        self.centroid = self.calculate_centroid()\n",
    "        self.converge = np.array_equal(old_centroid, self.centroid)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en el atributo centroid, se llama al método calculate_centroid() para asignarle el centroide al Cluster en función de la lista de puntos del Cluster. Este método calcula el centroide como el punto medio de todos los puntos que forman el Cluster.\n",
    "\n",
    "Por otro lado implementamos el método update_cluster(points), que es el método encargado de actualizar el estado del Cluster, calculando el nuevo centroide con los nuevos puntos del Cluster tras el paso de asignación y comprobando si convergen los centroides mirando el valor del centroide del paso anterior y del actual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def k_means(dataset, num_clusters, iterations):\n",
    "\n",
    "    points = dataset_to_list_points(dataset)\n",
    "\n",
    "    #J(c,µ) = ∑ || x^(i) - µc^(i)||^2\n",
    "    #Se inicializan varias veces los centroides y se toma el resultado con menor valor en la funcion de costos\n",
    "    #para evitar minimos locales\n",
    "\n",
    "    clusters_cost_min = None\n",
    "    cost_min = sys.float_info.max\n",
    "\n",
    "    for i in range(5):\n",
    "        # INICIALIZACIÓN: Selección aleatoria de N puntos y creación de los Clusters\n",
    "        initial = random.sample(points, num_clusters)\n",
    "        clusters = [Cluster([p]) for p in initial]\n",
    "\n",
    "        # Inicializamos una lista para el paso de asignación de objetos\n",
    "        new_points_cluster = [[] for i in range(num_clusters)]\n",
    "\n",
    "        converge = False\n",
    "        it_counter = 0\n",
    "        while (not converge) and (it_counter < iterations):\n",
    "            # ASIGNACION\n",
    "            for p in points:\n",
    "                i_cluster = get_nearest_cluster(clusters, p)\n",
    "                new_points_cluster[i_cluster].append(p)\n",
    "\n",
    "            # ACTUALIZACIÓN\n",
    "            for i, c in enumerate(clusters):\n",
    "                c.update_cluster(new_points_cluster[i])\n",
    "\n",
    "            # ¿CONVERGE?\n",
    "            converge = [c.converge for c in clusters].count(False) == 0\n",
    "\n",
    "            # Incrementamos el contador\n",
    "            it_counter += 1\n",
    "            new_points_cluster = [[] for i in range(num_clusters)]\n",
    "\n",
    "        cost = 0\n",
    "        for c in clusters:\n",
    "            cost = cost + c.cost_function()\n",
    "        if cost < cost_min:\n",
    "            cost_min = cost\n",
    "            clusters_cost_min = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando la funcion de costo J(c, µ) = ∑ ||x^(i) - µc^(i)||^2 se inicializan varias veces los centroides para evitar mínimos locales. Luego de realizar varias corridas con los distintos centroides inicializados aleatoriamente nos quedamos con la corrida que mejor valor dio en la función J.\n",
    "\n",
    "En primer lugar inicializamos ‘N’ Clusters (num_clusteres) seleccionando de forma aleatoria ‘N’ puntos del data set. Posteriormente iniciamos los pasos de asignación y actualización de los Clusters hasta que estos converjan o hasta que lleguemos al número máximo de iteraciones (iterations). Esto lo hacemos dentro del bucle “While”. En cada iteración asignamos cada uno de los puntos del data set al Cluster que tenga el centroide más cercano (Asignación) con el método get_nearest_cluster() que calcula la distancia euclídea entre el punto y el centroide y devuelve el índice del Cluster con centroide más cercano, y una vez asignados recalculamos los centroides de los Clusters. Posteriormente comprobamos la convergencia de los centroides para ver si seguimos iterando o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/Health-Tweets/*.txt'\n",
    "filenames = glob.glob (path)\n",
    "\n",
    "text = []\n",
    "for fname in filenames:\n",
    "    with open (fname,encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            text.append (line)\n",
    "\n",
    "vectorizer = CountVectorizer (encoding='latin-1', stop_words='english', min_df=20)\n",
    "vector = vectorizer.fit_transform (text)\n",
    "\n",
    "df = pd.DataFrame (data=vector.toarray ())\n",
    "points = df.as_matrix ().tolist()\n",
    "\n",
    "J = []\n",
    "J_sklearn = []\n",
    "max_iterations =10\n",
    "\n",
    "for n_clusters in range(10, 100, 10):\n",
    "\n",
    "    clusters = k_means(points, n_clusters, max_iterations)\n",
    "\n",
    "    kmeans = KMeans (n_clusters=n_clusters, max_iter=max_iterations, init='random')\n",
    "    kmeans.fit (points)\n",
    "\n",
    "    # Print final result\n",
    "    print_results (kmeans, clusters)\n",
    "\n",
    "    cost = 0\n",
    "    for c in clusters:\n",
    "        cost = cost + c.cost_function ()\n",
    "    cost_sklearn = kmeans.inertia_\n",
    "    J.append(cost)\n",
    "    J_sklearn.append(cost_sklearn)\n",
    "\n",
    "print_results2(J, J_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
